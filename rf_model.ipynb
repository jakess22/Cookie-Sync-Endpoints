{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C5IYTwUqXv_x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler  \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "df = pd.read_csv('graph_features.csv') \n",
        "# drop unused columns\n",
        "df = df.drop(columns='True')\n",
        "df = df.dropna()\n",
        "#print(df['label'].value_counts())\n",
        "\n",
        "# drop domain rows with unknown labels\n",
        "index_names = df[df['label'] == -1].index\n",
        "df.drop(index_names, inplace = True)\n",
        "\n",
        "# make X, y sets\n",
        "y = df['label']\n",
        "X = df.drop(labels=['0', 'label'], axis=1)\n",
        "    \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25)\n",
        "\n",
        "# scale features to be in [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# train and fit only from training data\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "tLbxpMgPX2AJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning:"
      ],
      "metadata": {
        "id": "h58uIBqmBSU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "max_features = ['none', 'sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(10, 150, num = 11)]\n",
        "max_depth.append(None)\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, n_iter=1000, cv=None, verbose=2, random_state=99)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ofBO36oBYFLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de384ee7-5d2e-4e50-c25a-2997bb3de8e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimal RandomSearch parameters: \n",
        "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 150, 'bootstrap': True}"
      ],
      "metadata": {
        "id": "g3JaaS_GC0OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [140, 150, 160, 170],\n",
        "    'min_samples_leaf': [2, 3, 4],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "\n",
        "clf_tune = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(estimator = clf_tune, param_grid = param_grid, \n",
        "                          cv = 5, n_jobs = -1, verbose = 2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "best_grid = grid_search.best_estimator_\n",
        "print(best_grid)"
      ],
      "metadata": {
        "id": "6et-1cx6DeaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-fold cross validation for 20 random seeds. Using optimal hyperparameters."
      ],
      "metadata": {
        "id": "D0_Q4zhADZ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn import metrics\n",
        "\n",
        "auc = []\n",
        "pr = []\n",
        "rc = []\n",
        "f1 = []\n",
        "feats = []\n",
        "test_score = []\n",
        "clf= RandomForestClassifier()\n",
        "for random_state in range(20):\n",
        "  clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=2, min_samples_split=8, max_features='sqrt', max_depth=150, bootstrap=True, random_state=random_state)\n",
        "\n",
        "  # AUC\n",
        "  curr_auc = cross_val_score(clf, X, y, cv=10, scoring='roc_auc')\n",
        "  # PR\n",
        "  curr_pr = cross_val_score(clf, X, y, cv=10, scoring='precision')\n",
        "  # RC\n",
        "  curr_rc = cross_val_score(clf, X, y, cv=10, scoring='recall')\n",
        "  # F1 \n",
        "  curr_f1 = cross_val_score(clf, X, y, cv=10, scoring='f1')\n",
        "\n",
        "  curr_test_score = cross_validate(clf, X, y, cv=10)\n",
        "  test_score.append(curr_test_score['test_score'])\n",
        "  curr_feats = clf.feature_importances_\n",
        "\n",
        "  auc.append(curr_auc)\n",
        "  pr.append(curr_pr)\n",
        "  rc.append(curr_rc)\n",
        "  f1.append(curr_f1)\n",
        "  feats.append(curr_feats)\n",
        "  print(random_state, \"done\")\n",
        "print(\"Mean AUC:\", np.mean(auc))\n",
        "print(\"Mean PR\", np.mean(pr))\n",
        "print(\"Mean RC\", np.mean(rc))\n",
        "print(\"Mean F1 score\", f1)\n",
        "print(\"Mean CV Test score\", np.mean(test_score))\n",
        "\n",
        "a = 0\n",
        "for x in feats:\n",
        "  a += x[0]\n",
        "b = 0\n",
        "for x in feats:\n",
        "  b += x[1]\n",
        "c = 0\n",
        "for x in feats:\n",
        "  c += x[2]\n",
        "d = 0\n",
        "for x in feats:\n",
        "  d += x[3]\n",
        "print(\"Feature informativity: [degree centrality, in-degree centr, out-degree centr, PageRank\")\n",
        "print(a / len(feats), b / len(feats), c / len(feats), d / len(feats))  "
      ],
      "metadata": {
        "id": "ZYeudT8BY-Yr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}